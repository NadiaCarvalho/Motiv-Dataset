{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4NllfTy7UAlOXbWlSYdTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadiaCarvalho/Motiv-Dataset/blob/main/Dataset_Construction_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note:\n",
        "Run Setup first, then restart and run all"
      ],
      "metadata": {
        "id": "2fHF6YFl05jp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "VnvLr9SBlfyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lEj9QhROOGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4d2f24-f06c-4d81-e409-54c9f693e4b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/AdapExperiments/Performance\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd /content/drive/MyDrive/AdapExperiments/Performance/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import altair\n",
        "\n",
        "print(altair.__version__)\n",
        "!pip install --upgrade altair anywidget -q"
      ],
      "metadata": {
        "id": "QCHUBNe5dfVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70738f76-5df4-4401-80fb-e77adc92f438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.5.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.5/765.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions and Loadings"
      ],
      "metadata": {
        "id": "LiZVUVeQliSj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IDp15lN79pl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Import Model\n",
        "import torch\n",
        "model1 = torch.jit.load(f'/content/drive/MyDrive/AdapExperiments/models/RAVE_MODELS/musicnet.ts')\n",
        "model2 = torch.jit.load(f'/content/drive/MyDrive/AdapExperiments/models/RAVE_MODELS/voice_vocalset_b2048_r48000_z16.ts')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get Latent Space\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def get_audio(path, model, sr=48000, samplingSize=None, normalize=False):\n",
        "  audio, sr = librosa.load(path, sr=sr)\n",
        "\n",
        "  if normalize:\n",
        "    audio = librosa.util.normalize(audio)\n",
        "\n",
        "  x = torch.from_numpy(audio)\n",
        "  x = x[None, None, :]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    z = model.encode(x)\n",
        "    reconst = model(x).squeeze(0).detach().numpy()\n",
        "\n",
        "  lat = z.squeeze(0).detach().numpy().T\n",
        "\n",
        "  if samplingSize is None or samplingSize == 1:\n",
        "    return x, z, reconst, lat\n",
        "\n",
        "  # regroup per sample samples\n",
        "  lat_df = pd.DataFrame(lat)\n",
        "  lat_ss = lat_df.groupby(np.arange(len(lat_df)) // samplingSize).mean().values\n",
        "\n",
        "  m = lat_ss.shape[0]\n",
        "  n = int(np.ceil(audio.shape[0] / lat_ss.shape[0]))\n",
        "  pads = m*n - audio.shape[0]\n",
        "\n",
        "  reconstp = reconst.squeeze(0)\n",
        "\n",
        "  if pads > 0:\n",
        "    samples = np.pad(audio.astype(float), (0, pads), mode='constant', constant_values=0)\n",
        "    reconstp = np.pad(reconstp.astype(float), (0, pads + (audio.shape[0] - reconstp.shape[0])), mode='constant', constant_values=0)\n",
        "  else:\n",
        "    samples = audio[:pads]\n",
        "    reconstp = reconstp[:pads]\n",
        "\n",
        "  samples = np.reshape(np.asarray(samples), (m,n))\n",
        "  rsamples = np.reshape(np.asarray(reconstp), (m,n))\n",
        "\n",
        "  return samples, z, rsamples, lat_ss"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jgGyhczjK1qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Functions\n",
        "import itertools\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE, MDS, Isomap, LocallyLinearEmbedding\n",
        "\n",
        "import altair as alt\n",
        "from altair import datum\n",
        "print(alt.__version__) # above 5.0\n",
        "\n",
        "def get_dimensionality_reduction(algorithm, latent_spaces, n_components=2):\n",
        "    if algorithm == 'pca':\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        pca = PCA(n_components=n_components)\n",
        "        predictions = pca.fit_transform(\n",
        "            StandardScaler().fit_transform(latent_spaces))\n",
        "    elif algorithm == 'tsne':\n",
        "        tsne = TSNE(n_components=n_components, perplexity=30 if len(latent_spaces) > 30 else len(latent_spaces)-1)\n",
        "        predictions = tsne.fit_transform(np.asarray(latent_spaces))\n",
        "    elif algorithm == 'mds':\n",
        "        mds = MDS(n_components=n_components, normalized_stress=\"auto\", max_iter=100)\n",
        "        predictions = mds.fit_transform(latent_spaces)\n",
        "    elif algorithm == 'isomap':\n",
        "        iso = Isomap(n_components=n_components)\n",
        "        predictions = iso.fit_transform(latent_spaces)\n",
        "    elif algorithm == 'lle':\n",
        "        lle = LocallyLinearEmbedding(n_components=n_components)\n",
        "        predictions = lle.fit_transform(latent_spaces)\n",
        "    else:\n",
        "        import umap\n",
        "        reducer = umap.UMAP(n_components=n_components)\n",
        "        predictions = reducer.fit_transform(latent_spaces)\n",
        "    return predictions\n",
        "\n",
        "def get_vegas_data(predictions, labels, radius=.01):\n",
        "  source = {\n",
        "      'source': ['_'.join(l.split('_')[0:-1]) for l in labels],\n",
        "      'stype': [l.split('_')[0] for l in labels],\n",
        "      'id_s': [l.split('_')[-1] for l in labels],\n",
        "      'id_s_o': [int(l.split('_')[-1]) for l in labels],\n",
        "  }\n",
        "  if len(predictions.shape) == 1:\n",
        "      source['x'] = [int(l.split('_')[-1]) for l in labels]\n",
        "      source['y'] = predictions\n",
        "  else:\n",
        "      source['x'] = predictions[:, 0]\n",
        "      source['y'] = predictions[:, 1]\n",
        "\n",
        "  return pd.DataFrame(source)\n",
        "\n",
        "def get_plot2(latsS, lats0, lats, dimensions=[0, 1], algorithm='lle'):\n",
        "  if len(latsS) == 0:\n",
        "    all_elements = np.vstack(tuple([lats0] + list(lats.values())))\n",
        "  else:\n",
        "    all_elements = np.vstack(tuple([latsS, lats0] + list(lats.values())))\n",
        "  #print(all_elements.shape)\n",
        "\n",
        "  if len(dimensions) > 2:\n",
        "      points = get_dimensionality_reduction(algorithm, all_elements[:, dimensions], 2)\n",
        "  elif len(dimensions) == 2:\n",
        "      points = all_elements[:, dimensions]\n",
        "  elif len(dimensions) == 1:\n",
        "      points = all_elements[:, dimensions[0]]\n",
        "  else:\n",
        "      points = get_dimensionality_reduction(algorithm, all_elements, 2)\n",
        "\n",
        "  def flatten_comprehension(matrix):\n",
        "    return [item for row in matrix for item in row]\n",
        "\n",
        "  return get_vegas_data(points, labels=[f'Score_{i}' for i in list(range(len(latsS)))]\n",
        "                        + [f'Original_{i}' for i in list(range(len(lats0)))] +\n",
        "   flatten_comprehension([[f'{n}_{i}' for i in list(range(len(l)))] for n, l in lats.items()]))\n",
        "\n",
        "def get_plot_all_equal(lats, dimensions=[0, 1], algorithm='lle'):\n",
        "  all_elements = np.vstack(list(lats.values()))\n",
        "  print(all_elements.shape)\n",
        "\n",
        "  if len(dimensions) > 2:\n",
        "      points = get_dimensionality_reduction(algorithm, all_elements[:, dimensions], 2)\n",
        "  elif len(dimensions) == 2:\n",
        "      points = all_elements[:, dimensions]\n",
        "  elif len(dimensions) == 1:\n",
        "      points = all_elements[:, dimensions[0]]\n",
        "  else:\n",
        "      points = get_dimensionality_reduction(algorithm, all_elements, 2)\n",
        "\n",
        "  def flatten_comprehension(matrix):\n",
        "    return [item for row in matrix for item in row]\n",
        "\n",
        "  return get_vegas_data(points, labels=flatten_comprehension([[f'{n}_{i}' for i in list(range(len(l)))] for n, l in lats.items()]))\n",
        "\n",
        "\n",
        "def plot_vegas_data(source, titleX=\"x\", titleY=\"y\"):\n",
        "\n",
        "  search_input = alt.selection_point(\n",
        "      fields=['id_s'],\n",
        "      empty=False,  # Start with no points selected\n",
        "      bind=alt.binding(\n",
        "          input='search',\n",
        "          placeholder='Grain',\n",
        "          name='Search ',\n",
        "      )\n",
        "  )\n",
        "  selection = alt.selection_interval(bind='scales')\n",
        "  highlight = alt.selection_point(\n",
        "    on=\"pointerover\", fields=[\"source\"], nearest=True\n",
        "  )\n",
        "\n",
        "  param_checkbox = alt.param(\n",
        "      bind=alt.binding_checkbox(name='View Trajectories:'),\n",
        "      name='Trajectories')\n",
        "  score_grain_checkbox = alt.param(\n",
        "      bind=alt.binding_checkbox(name='View Score Grains:'),\n",
        "      value=True,\n",
        "      name='ScoreGrain')\n",
        "\n",
        "  chart = alt.Chart(source[source['source'] != 'Score']).encode(\n",
        "    x=alt.X('x:Q', title=titleX),\n",
        "    y=alt.Y('y:Q', title=titleY),\n",
        "    color='stype:N',\n",
        "    tooltip=['source:N', 'id_s:N']\n",
        "  )\n",
        "  points = chart.mark_circle().encode(\n",
        "    opacity=alt.condition(\n",
        "        search_input,\n",
        "        alt.value(1),\n",
        "        alt.value(0.3)\n",
        "    )\n",
        "  ).add_params(\n",
        "      selection,\n",
        "      highlight,\n",
        "      search_input\n",
        "  ).properties(\n",
        "      name='Grains',width=800,height=500\n",
        "  )\n",
        "\n",
        "  # create marks for first and last points\n",
        "  lines = chart.mark_line().encode(\n",
        "      size=alt.condition(~highlight, alt.value(1), alt.value(2)),\n",
        "      opacity=alt.condition(\n",
        "        param_checkbox,\n",
        "        alt.value(1),\n",
        "        alt.value(0)\n",
        "    ),\n",
        "    strokeDash='source',\n",
        "    order=\"id_s_o:Q\",\n",
        "  ).add_params(\n",
        "      param_checkbox\n",
        "  ).properties(\n",
        "      name='Trajectories',width=800,height=500\n",
        "  )\n",
        "  circles = chart.mark_circle(size=60).encode(\n",
        "      opacity=alt.condition(\n",
        "        param_checkbox,\n",
        "        alt.value(1),\n",
        "        alt.value(0)\n",
        "      )\n",
        "  )\n",
        "  arrows = chart.mark_point(shape='wedge', size=60).encode(\n",
        "      opacity=alt.condition(\n",
        "        param_checkbox,\n",
        "        alt.value(1),\n",
        "        alt.value(0)\n",
        "      )\n",
        "  )\n",
        "\n",
        "  chartS = alt.Chart(source[source['source'] == 'Score']).encode(\n",
        "    x=alt.X('x:Q', title=titleX),\n",
        "    y=alt.Y('y:Q', title=titleY),\n",
        "    color='source:N',\n",
        "    tooltip=['source:N', 'id_s:N']\n",
        "  )\n",
        "  pointsS = chartS.mark_circle().encode(\n",
        "    opacity=alt.condition(\n",
        "        score_grain_checkbox,\n",
        "        alt.value(.2),\n",
        "        alt.value(0)\n",
        "    )\n",
        "  ).transform_filter(\n",
        "      datum.source == 'Score'\n",
        "  ).add_params(\n",
        "      selection,\n",
        "      score_grain_checkbox\n",
        "  ).properties(\n",
        "      name='Score',width=800,height=500\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  return pointsS, points, lines, circles, arrows\n"
      ],
      "metadata": {
        "id": "V8kSjG8xF0kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "cf419f66-2bd4-43b8-fdda-87397aaa8923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizations"
      ],
      "metadata": {
        "id": "mL6NocyZBW4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show Graphs\n",
        "\n",
        "import glob\n",
        "import time\n",
        "import tqdm.notebook as tqdm\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "score_audio, original_audio, selected_audios, model = None, None, None, model2\n",
        "\n",
        "model_selector = widgets.Select(options=['MusicNet', 'VocalSet'], description='Model', index=1)\n",
        "experiment_selector = widgets.IntSlider(1, 1, 3, 1, description='Experiment')\n",
        "phrase_selector = widgets.IntSlider(1, 1, 3, 1, description='Phrase')\n",
        "\n",
        "opts = sorted([x for x in glob.glob(f'PhraseRecordings/Experiment1/phrase_1/*.wav') if 'original' not in x])\n",
        "selector = widgets.SelectMultiple(options=opts,\n",
        "                                  value=opts[0:1], description='Phrase Type',\n",
        "                                  layout=widgets.Layout(width='75%', height='100px'),\n",
        "                                  style={'button_color': 'red'},)\n",
        "sample_size = widgets.IntSlider(4, 1, 12, 1.0, description='Spl Group')\n",
        "dimension_selector = widgets.SelectMultiple(options=list(range(16)), description='Dimensions', value=list(range(16)))\n",
        "\n",
        "startA = widgets.Button(description='Get Audios')\n",
        "startb = widgets.Button(description='Start')\n",
        "\n",
        "def on_change_exp(change):\n",
        "    global selector\n",
        "    phrase_selector.max = 4 if experiment_selector.value == 2 else 3\n",
        "    exp_name = 'Experiment1' if experiment_selector.value == 1 else 'Experiment2' if experiment_selector.value == 2 else 'Experiment1-Multiple'\n",
        "    opts = sorted([x for x in glob.glob(f'PhraseRecordings/{exp_name}/phrase_{phrase_selector.value}/*.wav') if 'original' not in x and 'electronics' not in x])\n",
        "    selector.options = opts\n",
        "\n",
        "def on_change(change):\n",
        "    global selector\n",
        "    exp_name = 'Experiment1' if experiment_selector.value == 1 else 'Experiment2' if experiment_selector.value == 2 else 'Experiment1-Multiple'\n",
        "    opts = sorted([x for x in glob.glob(f'PhraseRecordings/{exp_name}/phrase_{phrase_selector.value}/*.wav') if 'original' not in x and 'electronics' not in x])\n",
        "    selector.options = opts\n",
        "    selector.value = opts[0:1]\n",
        "\n",
        "def on_change_m(change):\n",
        "    global model\n",
        "    if model_selector.value == 'MusicNet':\n",
        "        model = model1\n",
        "    else:\n",
        "        model = model2\n",
        "\n",
        "    dimension_selector.options = list(range(16))\n",
        "\n",
        "experiment_selector.observe(on_change_exp)\n",
        "phrase_selector.observe(on_change)\n",
        "model_selector.observe(on_change_m)\n",
        "\n",
        "display(widgets.HBox([model_selector, dimension_selector]))\n",
        "display(widgets.HBox([experiment_selector, phrase_selector]))\n",
        "display(selector)\n",
        "display(sample_size)\n",
        "display(widgets.HBox([startA, startb]))\n",
        "\n",
        "out1 = widgets.Output(layout={'border': '0px solid black', 'padding': '.5em', 'width': '90%'})\n",
        "\n",
        "def on_startA(change):\n",
        "    global score_audio, original_audio, selected_audios\n",
        "\n",
        "    with out1:\n",
        "      clear_output(wait=False)\n",
        "      time.sleep(1)\n",
        "\n",
        "      print(f'\\nStarting latent space generation for Phrase {phrase_selector.value} with samplingSize {sample_size.value}')\n",
        "\n",
        "      print('Getting original audios')\n",
        "      if experiment_selector.value == 1:\n",
        "          original_audio = get_audio(f'PhraseRecordings/Experiment{experiment_selector.value}/phrase_{phrase_selector.value}/phrase_{phrase_selector.value}_original.wav', model, samplingSize=sample_size.value)\n",
        "          print('Original Phrase Done')\n",
        "          score_audio = get_audio('Lamento-Sax-Complete-Audio/Lamento-Take1.wav', model, samplingSize=sample_size)\n",
        "          print('Original Score Done')\n",
        "      elif experiment_selector.value == 3:\n",
        "          original_audio = get_audio(f'PhraseRecordings/Experiment1-Multiple/phrase_{phrase_selector.value}/OR_T01.wav', model, samplingSize=sample_size.value)\n",
        "          print('Original Phrase Done')\n",
        "          score_audio = [[],[],[],[]] #get_audio('Lamento-Sax-Complete-Audio/Lamento-Take3.wav', model, samplingSize=sample_size)\n",
        "          print('Original Score Done')\n",
        "      else:\n",
        "          original_audio = get_audio(f'PhraseRecordings/Experiment{experiment_selector.value}/phrase_{phrase_selector.value}/phrase_{phrase_selector.value}_electronics.wav', model, samplingSize=sample_size.value)\n",
        "          print('Original Phrase Done')\n",
        "          score_audio = get_audio('Audios/Lamento_Villa_Rojo.mpeg', model, samplingSize=sample_size)\n",
        "          print('Original Score Done')\n",
        "\n",
        "      print(f'Getting selected audios')\n",
        "      if experiment_selector.value == 3:\n",
        "        selected_audios = {v.split('/')[-1][:-4]:get_audio(v, model, samplingSize=sample_size.value) for v in tqdm(selector.value)}\n",
        "      else:\n",
        "        selected_audios = {'_'.join(v.split('/')[-1].split('_')[2:])[:-4]:get_audio(v, model, samplingSize=sample_size.value) for v in tqdm(selector.value)}\n",
        "\n",
        "def on_change2(change):\n",
        "    global model, original_audio, selected_audios\n",
        "\n",
        "    with out1:\n",
        "        clear_output(wait=False)\n",
        "        time.sleep(1)\n",
        "\n",
        "        print(f'Generating latent space visualization for dimensions {dimension_selector.value}')\n",
        "\n",
        "        source = get_plot2(score_audio[3], original_audio[3], {v:sa[3] for v, sa in selected_audios.items()}, dimension_selector.value, algorithm='tsne')\n",
        "        print('Extracted Source')\n",
        "\n",
        "        titleY = f\"Latent Dimension {dimension_selector.value[0]}\" if len(dimension_selector.value) == 1 else f\"Latent Dimension {dimension_selector.value[1]}\" if len(dimension_selector.value) == 2 else \"t-SNE 2\"\n",
        "        titleX = f\"Unit\" if len(dimension_selector.value) == 1 else f\"Latent Dimension {dimension_selector.value[0]}\" if len(dimension_selector.value) == 2 else \"t-SNE 1\"\n",
        "        scorep, points, lines, circleSt, arrowEnd = plot_vegas_data(source, titleX, titleY)\n",
        "        print('Extracted Plot')\n",
        "\n",
        "        max_R = max(source[source['source'] != 'Score']['id_s'].apply(func=lambda x: int(x)))\n",
        "        jchart = alt.JupyterChart(alt.layer(points + lines + circleSt.transform_filter((datum.id_s_o == 0)) + arrowEnd.transform_filter((datum.id_s_o == max_R))))\n",
        "        jchart.chart = jchart.chart.properties(width=800,height=500).interactive()\n",
        "\n",
        "        rangeR = widgets.IntRangeSlider(value=[0,max_R], min=0, max=max_R)\n",
        "        def on_change_range_R(change):\n",
        "          m = rangeR.value[0]\n",
        "          n = rangeR.value[1]\n",
        "\n",
        "          if len(dimension_selector.value) == 1:\n",
        "            jchart.chart =   (\n",
        "                points.encode(\n",
        "                x=alt.X('x:Q', title=titleX, scale=alt.Scale(domain=[m-1,n+1], nice=False))).transform_filter((datum.id_s_o >= m) & (datum.id_s_o <= n))\n",
        "                + lines.transform_filter((datum.id_s_o >= m) & (datum.id_s_o <= n))\n",
        "                ) + circleSt.transform_filter((datum.id_s_o == m)) + arrowEnd.transform_filter((datum.id_s_o == n))\n",
        "          else:\n",
        "            jchart.chart =   (\n",
        "                points.transform_filter((datum.id_s_o >= m) & (datum.id_s_o <= n))\n",
        "                + lines.transform_filter((datum.id_s_o >= m) & (datum.id_s_o <= n))\n",
        "                ) + circleSt.transform_filter((datum.id_s_o == m)) + arrowEnd.transform_filter((datum.id_s_o == n))\n",
        "\n",
        "          if len(dimension_selector.value) == 1:\n",
        "            jchart.chart\n",
        "\n",
        "          jchart.chart = jchart.chart.properties(width=800,height=500).interactive()\n",
        "\n",
        "        rangeR.observe(on_change_range_R)\n",
        "        display(rangeR)\n",
        "        time.sleep(1)\n",
        "        display(jchart)\n",
        "\n",
        "startA.on_click(on_startA)\n",
        "startb.on_click(on_change2)\n",
        "display(out1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323,
          "referenced_widgets": [
            "5270a5d8eda2424186af1aa71a586ae6",
            "383b3dafd7e042e8abaa41bc5e1959a6",
            "b76823fca6c64a3f9e26632c50167442",
            "2df796fc938a44f39be823724f4abbe9",
            "698796d5bcec45b5a96c7bc99f3435b8",
            "4ae14772bfe141298ce99fcec69434fa",
            "84fd88294ac542e4b6ebc300265d73f8",
            "ed15eefcc03d4a00b94f8c41cef165e0",
            "677ce80d225946caa0ddfbee6ca7ad40",
            "8f6953766b6a4740922f9b44a56bb733",
            "7b6e72acc26446dcaa85485dd6c021b4",
            "a1cf0724ee2a40bbaef5994149277db9",
            "9e25a439e04b440996a628d4c6b59d6f",
            "acdcb2932b8145e1ac5ffa2fb9b79fe6",
            "dbd5962559c1498eaa24c6e981dd786a",
            "4fcf452bb6ae46a2b3d68dc5760a666a",
            "88148319b24948f4af013bd55b9f5082",
            "61188021290c40a78a9c5954d7adaa4b",
            "c055d9724abc4e0cbe471019d8c25709",
            "fe3971a37b24487db3f58f1db89274e8",
            "b027aedba94b4ce3968ae37b55e173e6",
            "9a34e642280c43b6894507ae49e21b24",
            "ed009eb076a84c97a7e7df00da7a7140",
            "e55a3f6b0e3b49acab6aaa23e100f57c",
            "c0302b2331484877a3a8942fa70fe9f8",
            "39a482d84f044f5ea85e74c62d64d5a3",
            "c87ddcbc2ccc4b189ddd6f89cae4b9ba",
            "b403181a2d154530ae6f903fc3521d10",
            "c1ad763c876b454791d46f4b33f9c951",
            "8761bf8deff646a9ae279ed75deebcd7",
            "404f3f904a904cf499338b8f72dbe136",
            "6ae7fc84bba74168b257567630b390ba"
          ]
        },
        "id": "jZSHIghnIWkY",
        "outputId": "cd8e4895-fcc3-44cb-e987-4864964fe97a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Select(description='Model', index=1, options=('MusicNet', 'VocalSet'), value='VocalSet'), Selec…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5270a5d8eda2424186af1aa71a586ae6"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(IntSlider(value=1, description='Experiment', max=3, min=1), IntSlider(value=1, description='Phr…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fcf452bb6ae46a2b3d68dc5760a666a"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SelectMultiple(description='Phrase Type', layout=Layout(height='100px', width='75%'), options=(), value=())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88148319b24948f4af013bd55b9f5082"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntSlider(value=4, description='Spl Group', max=12, min=1)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe3971a37b24487db3f58f1db89274e8"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Button(description='Get Audios', style=ButtonStyle()), Button(description='Start', style=Button…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8761bf8deff646a9ae279ed75deebcd7"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output(layout=Layout(border='0px solid black', padding='.5em', width='90%'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ae7fc84bba74168b257567630b390ba"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Construction"
      ],
      "metadata": {
        "id": "RL6ZAD6uBkFm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNFckF8JBVjo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}